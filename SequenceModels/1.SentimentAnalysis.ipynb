{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eM2WI45DjCVp"
   },
   "source": [
    "## Sentiment with Deep Neural Networks\n",
    "\n",
    "explore sentiment analysis using deep neural networks. \n",
    "- Trax source code can be found on Github: [Trax](https://github.com/google/trax)\n",
    "- The Trax code also uses the JAX library: [JAX](https://jax.readthedocs.io/en/latest/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "WOTfm2P0jCVt",
    "outputId": "d4903011-7268-4bea-ae35-ea3fd0b46311"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import random as rnd\n",
    "import trax\n",
    "\n",
    "trax.supervised.trainer_lib.init_random_number_generators(31)\n",
    "\n",
    "import trax.fastmath.numpy as np\n",
    "from trax import layers as tl\n",
    "from utils import Layer, load_tweets, process_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CZ8RUynQsktn"
   },
   "source": [
    "##  Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "h5ClwIOSuLJh",
    "outputId": "dee50364-c476-405f-8cdd-63d067b848d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of positive tweets: 5000\n",
      "The number of negative tweets: 5000\n",
      "length of train_x 8000\n",
      "length of val_x 2000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load positive and negative tweets\n",
    "all_positive_tweets, all_negative_tweets = load_tweets()\n",
    "\n",
    "print(f\"The number of positive tweets: {len(all_positive_tweets)}\")\n",
    "print(f\"The number of negative tweets: {len(all_negative_tweets)}\")\n",
    "\n",
    "# Split positive & negativeset into validation and training\n",
    "val_pos   = all_positive_tweets[4000:]\n",
    "train_pos  = all_positive_tweets[:4000]\n",
    "\n",
    "val_neg   = all_negative_tweets[4000:]\n",
    "train_neg  = all_negative_tweets[:4000]\n",
    "\n",
    "train_x = train_pos + train_neg \n",
    "val_x  = val_pos + val_neg\n",
    "\n",
    "# Set the labels for the training set (1 for positive, 0 for negative)\n",
    "train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
    "\n",
    "# Set the labels for the validation set (1 for positive, 0 for negative)\n",
    "val_y  = np.append(np.ones(len(val_pos)), np.zeros(len(val_neg)))\n",
    "\n",
    "print(f\"length of train_x {len(train_x)}\")\n",
    "print(f\"length of val_x {len(val_x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "2bRX6aPDjCWH",
    "outputId": "09497362-bf73-4d63-e99f-460027e91eb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tweet at training position 0\n",
      "#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
      "Tweet at training position 0 after processing:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "print(\"original tweet at training position 0\")\n",
    "print(train_pos[0])\n",
    "\n",
    "print(\"Tweet at training position 0 after processing:\")\n",
    "process_tweet(train_pos[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ac4D5WSUAVub"
   },
   "source": [
    "###  Building the vocabulary\n",
    "\n",
    "The vocabulary will also include some special tokens\n",
    "- `__PAD__`: padding\n",
    "- `</e>`: end of line\n",
    "- `__UNK__`: a token representing any word that is not in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rQaHKs7kAVuc",
    "outputId": "1d360f94-902d-471c-d3c3-0d69c27f5eaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in vocab are 9088\n"
     ]
    }
   ],
   "source": [
    "Vocab = {'__PAD__': 0, '__</e>__': 1, '__UNK__': 2} \n",
    "\n",
    "# Note that we build vocab using training data\n",
    "for tweet in train_x: \n",
    "    processed_tweet = process_tweet(tweet)\n",
    "    for word in processed_tweet:\n",
    "        if word not in Vocab: \n",
    "            Vocab[word] = len(Vocab)\n",
    "    \n",
    "print(\"Total words in vocab are\",len(Vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0x8pND8tAVuf"
   },
   "source": [
    "###  Converting a tweet to a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ft1zNGMaAVuf"
   },
   "outputs": [],
   "source": [
    "# takes in a tweet and converts it to an array of numbers\n",
    "def tweet_to_tensor(tweet, vocab_dict, unk_token='__UNK__', verbose=False):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet - A string containing a tweet\n",
    "        vocab_dict - The words dictionary\n",
    "        unk_token - The special string for unknown tokens\n",
    "        verbose - Print info durign runtime\n",
    "    Output:\n",
    "        tensor_l - A python list with\n",
    "        \n",
    "    '''  \n",
    "\n",
    "    word_l = process_tweet(tweet)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"List of words from the processed tweet:\")\n",
    "        print(word_l)\n",
    "        \n",
    "    tensor_l = []\n",
    "    unk_ID = vocab_dict[unk_token]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"The unique integer ID for the unk_token is {unk_ID}\")\n",
    "\n",
    "    for word in word_l:\n",
    "        word_ID = vocab_dict[word] if word in vocab_dict else unk_ID\n",
    "        tensor_l.append(word_ID) \n",
    "    \n",
    "    return tensor_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "ze0Zx_5UjCWU",
    "outputId": "a9427907-b364-4c5f-fed5-bd2502e18bab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual tweet is\n",
      " Bro:U wan cut hair anot,ur hair long Liao bo\n",
      "Me:since ord liao,take it easy lor treat as save $ leave it longer :)\n",
      "Bro:LOL Sibei xialan\n",
      "\n",
      "Tensor of tweet:\n",
      " [1065, 136, 479, 2351, 745, 8148, 1123, 745, 53, 2, 2672, 791, 2, 2, 349, 601, 2, 3489, 1017, 597, 4559, 9, 1065, 157, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual tweet is\\n\", val_pos[0])\n",
    "print(\"\\nTensor of tweet:\\n\", tweet_to_tensor(val_pos[0], vocab_dict=Vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rwAZZIYYAVuj"
   },
   "source": [
    "###  Creating a batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fPd9HNT7AVuk"
   },
   "outputs": [],
   "source": [
    "# Data generator\n",
    "def data_generator(data_pos, data_neg, batch_size, loop, vocab_dict, shuffle=False):\n",
    "    '''\n",
    "    Input: \n",
    "        data_pos - Set of posstive examples\n",
    "        data_neg - Set of negative examples\n",
    "        batch_size - number of samples per batch. Must be even\n",
    "        loop - True or False\n",
    "        vocab_dict - The words dictionary\n",
    "        shuffle - Shuffle the data order\n",
    "    Yield:\n",
    "        inputs - Subset of positive and negative examples\n",
    "        targets - The corresponding labels for the subset\n",
    "        example_weights - An array specifying the importance of each example\n",
    "        \n",
    "    '''     \n",
    "\n",
    "    # batch size is an even number to allow an equal number of positive and negative samples\n",
    "    assert batch_size % 2 == 0\n",
    "    \n",
    "    # Number of positive (negative) examples in each batch\n",
    "    n_to_take = batch_size // 2\n",
    "    \n",
    "    pos_index = 0\n",
    "    neg_index = 0\n",
    "    \n",
    "    len_data_pos = len(data_pos)\n",
    "    len_data_neg = len(data_neg)\n",
    "    \n",
    "    pos_index_lines = list(range(len_data_pos))\n",
    "    neg_index_lines = list(range(len_data_neg))\n",
    "    \n",
    "    if shuffle:\n",
    "        rnd.shuffle(pos_index_lines)\n",
    "        rnd.shuffle(neg_index_lines)\n",
    "        \n",
    "    stop = False\n",
    "    \n",
    "    while not stop:  \n",
    "        batch = []\n",
    "        \n",
    "        # Pack n_to_take positive examples\n",
    "        \n",
    "        for i in range(n_to_take):\n",
    "             if pos_index >= len_data_pos: \n",
    "                if not loop:\n",
    "                    stop = True;\n",
    "                    break;\n",
    "                pos_index = 0\n",
    "                \n",
    "                if shuffle:\n",
    "                    rnd.shuffle(pos_index_lines)\n",
    "                    \n",
    "            tweet = data_pos[pos_index_lines[pos_index]]\n",
    "            tensor = tweet_to_tensor(tweet, vocab_dict)\n",
    "            batch.append(tensor)\n",
    "            pos_index = pos_index + 1\n",
    "\n",
    "\n",
    "        #Pack n_to_take negative examples\n",
    "    \n",
    "        for i in range(n_to_take):\n",
    "            if neg_index >= len_data_neg:\n",
    "                if not loop:\n",
    "                    stop = True;\n",
    "                    break;\n",
    "                neg_index = 0\n",
    "                \n",
    "                if shuffle:\n",
    "                    rnd.shuffle(neg_index_lines)\n",
    "\n",
    "            tweet = data_neg[neg_index_lines[neg_index]]\n",
    "            tensor = tweet_to_tensor(tweet, vocab_dict)\n",
    "            batch.append(tensor)\n",
    "            neg_index += 1\n",
    "\n",
    "        if stop:\n",
    "            break;\n",
    "\n",
    "        # Update the start index\n",
    "        pos_index += n_to_take\n",
    "        neg_index += n_to_take\n",
    "        \n",
    "        max_len = max([len(t) for t in batch]) \n",
    "        tensor_pad_l = []\n",
    "\n",
    "        for tensor in batch:\n",
    "            n_pad = max_len-len(tensor)\n",
    "            pad_l = [0]*n_pad\n",
    "            tensor_pad = tensor+pad_l\n",
    "            tensor_pad_l.append(tensor_pad)\n",
    "\n",
    "        inputs = np.array(tensor_pad_l)\n",
    "  \n",
    "        # Generate the list of targets\n",
    "        target_pos = [1]*n_to_take\n",
    "        target_neg = [0]*n_to_take\n",
    "        \n",
    "        # Concatenate the positve and negative targets\n",
    "        target_l = target_pos+target_neg\n",
    "        targets = np.array(target_l)\n",
    "        example_weights = np.ones_like(targets)\n",
    "        \n",
    "        yield inputs, targets, example_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "iIwM4YHtAVum",
    "outputId": "d25aa4ae-bad3-41f5-963c-0a091f8fb108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: [[2005 4451 3201    9    0    0    0    0    0    0    0]\n",
      " [4954  567 2000 1454 5174 3499  141 3499  130  459    9]\n",
      " [3761  109  136  583 2930 3969    0    0    0    0    0]\n",
      " [ 250 3761    0    0    0    0    0    0    0    0    0]]\n",
      "Targets: [1 1 0 0]\n",
      "Example Weights: [1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Set the random number generator for the shuffle procedure\n",
    "rnd.seed(30) \n",
    "\n",
    "# Create the training data generator\n",
    "def train_generator(batch_size, shuffle = False):\n",
    "    return data_generator(train_pos, train_neg, batch_size, True, Vocab, shuffle)\n",
    "\n",
    "# Create the validation data generator\n",
    "def val_generator(batch_size, shuffle = False):\n",
    "    return data_generator(val_pos, val_neg, batch_size, True, Vocab, shuffle)\n",
    "\n",
    "# Create the validation data generator\n",
    "def test_generator(batch_size, shuffle = False):\n",
    "    return data_generator(val_pos, val_neg, batch_size, False, Vocab, shuffle)\n",
    "\n",
    "# Get a batch from the train_generator and inspect.\n",
    "inputs, targets, example_weights = next(train_generator(4, shuffle=True))\n",
    "\n",
    "print(f'Inputs: {inputs}')\n",
    "print(f'Targets: {targets}')\n",
    "print(f'Example Weights: {example_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "mcDOyrx9jCWh",
    "outputId": "1adae96d-fb14-4cc6-d39e-7e4d9517c239"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inputs shape is (4, 14)\n",
      "The targets shape is (4,)\n",
      "The example weights shape is (4,)\n",
      "input tensor: [3 4 5 6 7 8 9 0 0 0 0 0 0 0]; target 1; example weights 1\n",
      "input tensor: [10 11 12 13 14 15 16 17 18 19 20  9 21 22]; target 1; example weights 1\n",
      "input tensor: [5738 2901 3761    0    0    0    0    0    0    0    0    0    0    0]; target 0; example weights 1\n",
      "input tensor: [ 858  256 3652 5739  307 4458  567 1230 2767  328 1202 3761    0    0]; target 0; example weights 1\n"
     ]
    }
   ],
   "source": [
    "# Test the train_generator\n",
    "\n",
    "tmp_data_gen = train_generator(batch_size = 4)\n",
    "tmp_inputs, tmp_targets, tmp_example_weights = next(tmp_data_gen)\n",
    "\n",
    "print(f\"The inputs shape is {tmp_inputs.shape}\")\n",
    "print(f\"The targets shape is {tmp_targets.shape}\")\n",
    "print(f\"The example weights shape is {tmp_example_weights.shape}\")\n",
    "\n",
    "for i,t in enumerate(tmp_inputs):\n",
    "    print(f\"input tensor: {t}; target {tmp_targets[i]}; example weights {tmp_example_weights[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X591GrH_stXq"
   },
   "source": [
    "###  Defining classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TcWUXFaPzS-m"
   },
   "source": [
    "### ReLU class\n",
    "implement the ReLU activation function in a class below. The ReLU function looks as follows: \n",
    "\n",
    "$$ \\mathrm{ReLU}(x) = \\mathrm{max}(0,x) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VGE5zZ5mzF9x"
   },
   "outputs": [],
   "source": [
    "class Relu(Layer):\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Input: \n",
    "            - x (a numpy array): the input\n",
    "        Output:\n",
    "            - activation (numpy array): all positive or 0 version of x\n",
    "        '''\n",
    "    \n",
    "        activation = np.maximum(x,0)\n",
    "        \n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "hVQ3YtoZ1uYP",
    "outputId": "6565529b-abe1-4b01-f5a8-36f8c7d0d903"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data is:\n",
      "[[-2. -1.  0.]\n",
      " [ 0.  1.  2.]]\n",
      "Output of Relu is:\n",
      "[[0. 0. 0.]\n",
      " [0. 1. 2.]]\n"
     ]
    }
   ],
   "source": [
    "# Test relu function\n",
    "x = np.array([[-2.0, -1.0, 0.0], [0.0, 1.0, 2.0]], dtype=float)\n",
    "relu_layer = Relu()\n",
    "print(\"Test data is:\")\n",
    "print(x)\n",
    "print(\"Output of Relu is:\")\n",
    "print(relu_layer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XepjDxCQ1G8p"
   },
   "source": [
    "###  Dense class \n",
    "\n",
    "Implement the function of the Dense class. \n",
    "- The forward function multiplies the input to the layer (`x`) by the weight matrix (`W`)\n",
    "\n",
    "$$\\mathrm{forward}(\\mathbf{x},\\mathbf{W}) = \\mathbf{xW} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cJqiv5KnjCWr"
   },
   "outputs": [],
   "source": [
    "from trax import fastmath\n",
    "np = fastmath.numpy\n",
    "random = fastmath.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "783FfWt70660"
   },
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    \"\"\"\n",
    "    A dense (fully-connected) layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_units, init_stdev=0.1):\n",
    "        \n",
    "        self._n_units = n_units\n",
    "        self._init_stdev = init_stdev\n",
    "\n",
    "    def forward(self, x):\n",
    "        dense = np.dot(x,self.weights) \n",
    "        return dense\n",
    "\n",
    "    def init_weights_and_state(self, input_signature, random_key):\n",
    "        input_shape = input_signature.shape\n",
    "        w = self._init_stdev*random.normal(key=random_key, shape=(input_shape[-1], self._n_units))\n",
    "        self.weights = w\n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "vw-z6n8SAVuy",
    "outputId": "60b4a7ca-f8b6-4dce-9a35-b72eba48db1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights are\n",
      "  [[-0.02837108  0.09368162 -0.10050076  0.14165013  0.10543301  0.09108126\n",
      "  -0.04265672  0.0986188  -0.05575325  0.00153249]\n",
      " [-0.20785688  0.0554837   0.09142365  0.05744595  0.07227863  0.01210617\n",
      "  -0.03237354  0.16234995  0.02450038 -0.13809784]\n",
      " [-0.06111237  0.01403724  0.08410042 -0.1094358  -0.10775021 -0.11396459\n",
      "  -0.05933381 -0.01557652 -0.03832145 -0.11144515]]\n",
      "Foward function output is  [[-3.0395496   0.9266802   2.5414743  -2.050473   -1.9769388  -2.582209\n",
      "  -1.7952735   0.94427425 -0.8980402  -3.7497487 ]]\n"
     ]
    }
   ],
   "source": [
    "# Testing Dense layer \n",
    "dense_layer = Dense(n_units=10)  #sets  number of units in dense layer\n",
    "random_key = random.get_prng(seed=0)  # sets random seed\n",
    "z = np.array([[2.0, 7.0, 25.0]]) # input array \n",
    "\n",
    "dense_layer.init(z, random_key)\n",
    "print(\"Weights are\\n \",dense_layer.weights)\n",
    "print(\"Foward function output is \", dense_layer(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eZEY8vBCgrgy"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wh33Hk8lgrgz"
   },
   "outputs": [],
   "source": [
    "# Implement the classifier function\n",
    "def classifier(vocab_size=len(Vocab), embedding_dim=256, output_dim=2, mode='train'):\n",
    "\n",
    "    # create embedding layer\n",
    "    embed_layer = tl.Embedding(\n",
    "        vocab_size=vocab_size, # Size of the vocabulary\n",
    "        d_feature=embedding_dim)  # Embedding dimension\n",
    "    \n",
    "    # Create a mean layer, to create an \"average\" word embedding\n",
    "    mean_layer = tl.Mean(axis=1)\n",
    "    \n",
    "    # Create a dense layer, one unit for each output\n",
    "    dense_output_layer = tl.Dense(n_units = output_dim)\n",
    "\n",
    "    # Create the log softmax layer (no parameters needed)\n",
    "    log_softmax_layer = tl.LogSoftmax()\n",
    "    \n",
    "    # combine all layers and create the classifier\n",
    "    model = tl.Serial(\n",
    "        embed_layer, # embedding layer\n",
    "        mean_layer, # mean layer\n",
    "        dense_output_layer, # dense output layer \n",
    "        log_softmax_layer  # log softmax layer\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OwJCu3e9jCXK"
   },
   "outputs": [],
   "source": [
    "tmp_model = classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "ZsMzvK8YjCXM",
    "outputId": "dbc365af-2a5a-4423-98f1-371d2ee6bba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'trax.layers.combinators.Serial'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Serial[\n",
       "  Embedding_9088_256\n",
       "  Mean\n",
       "  Dense_2\n",
       "  LogSoftmax\n",
       "]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(type(tmp_model))\n",
    "display(tmp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1FaugA_7grg6"
   },
   "source": [
    "## Training\n",
    "\n",
    "This defines a model trained using tl.CrossEntropyLoss optimized with the trax.optimizers.Adam optimizer, all the while tracking the accuracy using tl.Accuracy metric & tl.CrossEntropyLoss on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ogMtJgHSoiZj"
   },
   "outputs": [],
   "source": [
    "from trax.supervised import training\n",
    "\n",
    "batch_size = 16\n",
    "rnd.seed(271)\n",
    "\n",
    "train_task = training.TrainTask(\n",
    "    labeled_data=train_generator(batch_size=batch_size, shuffle=True),\n",
    "    loss_layer=tl.CrossEntropyLoss(),\n",
    "    optimizer=trax.optimizers.Adam(0.01),\n",
    "    n_steps_per_checkpoint=10,\n",
    ")\n",
    "\n",
    "eval_task = training.EvalTask(\n",
    "    labeled_data=val_generator(batch_size=batch_size, shuffle=True),\n",
    "    metrics=[tl.CrossEntropyLoss(), tl.Accuracy()],\n",
    ")\n",
    "\n",
    "model = classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CNx4LnP9rMsO",
    "outputId": "359fab84-7b89-4eea-b64e-5c681f6952c1"
   },
   "outputs": [],
   "source": [
    "output_dir = '~/model/'\n",
    "output_dir_expand = os.path.expanduser(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tolygrj7rpFX"
   },
   "outputs": [],
   "source": [
    "def train_model(classifier, train_task, eval_task, n_steps, output_dir):\n",
    "    '''\n",
    "    Input: \n",
    "        classifier - the model you are building\n",
    "        train_task - Training task\n",
    "        eval_task - Evaluation task\n",
    "        n_steps - the evaluation steps\n",
    "        output_dir - folder to save your files\n",
    "    Output:\n",
    "        trainer -  trax trainer\n",
    "    '''\n",
    "    training_loop = training.Loop(\n",
    "                                classifier, # The learning model\n",
    "                                train_task, # The training task\n",
    "                                eval_task = eval_task, # The evaluation task\n",
    "                                output_dir = output_dir) # The output directory\n",
    "\n",
    "    training_loop.run(n_steps = n_steps)\n",
    "\n",
    "    return training_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "d-AtiqAYs_rH",
    "outputId": "32fd06b6-9d04-4391-fe3a-689a28734b72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step      1: train CrossEntropyLoss |  0.88939196\n",
      "Step      1: eval  CrossEntropyLoss |  0.68833977\n",
      "Step      1: eval          Accuracy |  0.50000000\n",
      "Step     10: train CrossEntropyLoss |  0.61036736\n",
      "Step     10: eval  CrossEntropyLoss |  0.52182281\n",
      "Step     10: eval          Accuracy |  0.68750000\n",
      "Step     20: train CrossEntropyLoss |  0.34137666\n",
      "Step     20: eval  CrossEntropyLoss |  0.20654774\n",
      "Step     20: eval          Accuracy |  1.00000000\n",
      "Step     30: train CrossEntropyLoss |  0.20208922\n",
      "Step     30: eval  CrossEntropyLoss |  0.21594886\n",
      "Step     30: eval          Accuracy |  0.93750000\n",
      "Step     40: train CrossEntropyLoss |  0.19611198\n",
      "Step     40: eval  CrossEntropyLoss |  0.17582777\n",
      "Step     40: eval          Accuracy |  1.00000000\n",
      "Step     50: train CrossEntropyLoss |  0.11203773\n",
      "Step     50: eval  CrossEntropyLoss |  0.07589275\n",
      "Step     50: eval          Accuracy |  1.00000000\n",
      "Step     60: train CrossEntropyLoss |  0.09375446\n",
      "Step     60: eval  CrossEntropyLoss |  0.09290724\n",
      "Step     60: eval          Accuracy |  1.00000000\n",
      "Step     70: train CrossEntropyLoss |  0.08785903\n",
      "Step     70: eval  CrossEntropyLoss |  0.09610598\n",
      "Step     70: eval          Accuracy |  1.00000000\n",
      "Step     80: train CrossEntropyLoss |  0.08858261\n",
      "Step     80: eval  CrossEntropyLoss |  0.02319432\n",
      "Step     80: eval          Accuracy |  1.00000000\n",
      "Step     90: train CrossEntropyLoss |  0.05699894\n",
      "Step     90: eval  CrossEntropyLoss |  0.01778970\n",
      "Step     90: eval          Accuracy |  1.00000000\n",
      "Step    100: train CrossEntropyLoss |  0.03663783\n",
      "Step    100: eval  CrossEntropyLoss |  0.00210550\n",
      "Step    100: eval          Accuracy |  1.00000000\n"
     ]
    }
   ],
   "source": [
    "training_loop = train_model(model, train_task, eval_task, 100, output_dir_expand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVMcsw2kjCX9"
   },
   "source": [
    "###  Practice Making a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "WAMgXWY4jCX-",
    "outputId": "7d732b79-6528-49cf-a78a-2f3ee4891681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch is a tuple of length 3 because position 0 contains the tweets, and position 1 contains the targets.\n",
      "The shape of the tweet tensors is (16, 15) (num of examples, length of tweet tensors)\n",
      "The shape of the labels is (16,), which is the batch size.\n",
      "The shape of the example_weights is (16,), which is the same as inputs/targets size.\n"
     ]
    }
   ],
   "source": [
    "# Create a generator object\n",
    "tmp_train_generator = train_generator(16)\n",
    "\n",
    "# get one batch\n",
    "tmp_batch = next(tmp_train_generator)\n",
    "\n",
    "tmp_inputs, tmp_targets, tmp_example_weights = tmp_batch\n",
    "\n",
    "print(f\"The batch is a tuple of length {len(tmp_batch)} because position 0 contains the tweets, and position 1 contains the targets.\") \n",
    "print(f\"The shape of the tweet tensors is {tmp_inputs.shape} (num of examples, length of tweet tensors)\")\n",
    "print(f\"The shape of the labels is {tmp_targets.shape}, which is the batch size.\")\n",
    "print(f\"The shape of the example_weights is {tmp_example_weights.shape}, which is the same as inputs/targets size.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "5XoxD6u5jCX_",
    "outputId": "d857441c-0977-411f-a8de-2037820d8fa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction shape is (16, 2), num of tensor_tweets as rows\n",
      "Column 0 is the probability of a negative sentiment (class 0)\n",
      "Column 1 is the probability of a positive sentiment (class 1)\n",
      "\n",
      "View the prediction array\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[-4.9417334e+00, -7.1678162e-03],\n",
       "             [-6.5846415e+00, -1.3823509e-03],\n",
       "             [-5.4463043e+00, -4.3215752e-03],\n",
       "             [-4.3487482e+00, -1.3007164e-02],\n",
       "             [-4.9131694e+00, -7.3764324e-03],\n",
       "             [-4.7097692e+00, -9.0477467e-03],\n",
       "             [-5.2801600e+00, -5.1045418e-03],\n",
       "             [-4.1103225e+00, -1.6538620e-02],\n",
       "             [-1.8327236e-03, -6.3028107e+00],\n",
       "             [-4.7376156e-03, -5.3545618e+00],\n",
       "             [-3.4697056e-03, -5.6654320e+00],\n",
       "             [-1.1444092e-05, -1.1379558e+01],\n",
       "             [-1.0051131e-02, -4.6050973e+00],\n",
       "             [-1.0130405e-03, -6.8951964e+00],\n",
       "             [-6.1047077e-03, -5.1017356e+00],\n",
       "             [-7.4422359e-03, -4.9043016e+00]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feed the tweet tensors into the model to get a prediction\n",
    "tmp_pred = training_loop.eval_model(tmp_inputs)\n",
    "print(f\"The prediction shape is {tmp_pred.shape}, num of tensor_tweets as rows\")\n",
    "print(\"Column 0 is the probability of a negative sentiment (class 0)\")\n",
    "print(\"Column 1 is the probability of a positive sentiment (class 1)\")\n",
    "print()\n",
    "print(\"View the prediction array\")\n",
    "tmp_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "6wJHv0TNjCYC",
    "outputId": "0367db61-6e29-44b5-be45-7534600e6931"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg log prob -4.9417\tPos log prob -0.0072\t is positive? True\t actual 1\n",
      "Neg log prob -6.5846\tPos log prob -0.0014\t is positive? True\t actual 1\n",
      "Neg log prob -5.4463\tPos log prob -0.0043\t is positive? True\t actual 1\n",
      "Neg log prob -4.3487\tPos log prob -0.0130\t is positive? True\t actual 1\n",
      "Neg log prob -4.9132\tPos log prob -0.0074\t is positive? True\t actual 1\n",
      "Neg log prob -4.7098\tPos log prob -0.0090\t is positive? True\t actual 1\n",
      "Neg log prob -5.2802\tPos log prob -0.0051\t is positive? True\t actual 1\n",
      "Neg log prob -4.1103\tPos log prob -0.0165\t is positive? True\t actual 1\n",
      "Neg log prob -0.0018\tPos log prob -6.3028\t is positive? False\t actual 0\n",
      "Neg log prob -0.0047\tPos log prob -5.3546\t is positive? False\t actual 0\n",
      "Neg log prob -0.0035\tPos log prob -5.6654\t is positive? False\t actual 0\n",
      "Neg log prob -0.0000\tPos log prob -11.3796\t is positive? False\t actual 0\n",
      "Neg log prob -0.0101\tPos log prob -4.6051\t is positive? False\t actual 0\n",
      "Neg log prob -0.0010\tPos log prob -6.8952\t is positive? False\t actual 0\n",
      "Neg log prob -0.0061\tPos log prob -5.1017\t is positive? False\t actual 0\n",
      "Neg log prob -0.0074\tPos log prob -4.9043\t is positive? False\t actual 0\n"
     ]
    }
   ],
   "source": [
    "# turn probabilites into category predictions\n",
    "tmp_is_positive = tmp_pred[:,1] > tmp_pred[:,0]\n",
    "for i, p in enumerate(tmp_is_positive):\n",
    "    print(f\"Neg log prob {tmp_pred[i,0]:.4f}\\tPos log prob {tmp_pred[i,1]:.4f}\\t is positive? {p}\\t actual {tmp_targets[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fRRrgOHJgrhI"
   },
   "source": [
    "## Evaluation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WBqaN5f9grhJ"
   },
   "outputs": [],
   "source": [
    "# compute accuracy of a batch\n",
    "def compute_accuracy(preds, y, y_weights):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        preds: a tensor of shape (dim_batch, output_dim) \n",
    "        y: a tensor of shape (dim_batch, output_dim) with the true labels\n",
    "        y_weights: a n.ndarray with the a weight for each example\n",
    "    Output: \n",
    "        accuracy: a float between 0-1 \n",
    "        weighted_num_correct (np.float32): Sum of the weighted correct predictions\n",
    "        sum_weights (np.float32): Sum of the weights\n",
    "    \"\"\"\n",
    "\n",
    "    is_pos =  preds[:,1] > preds[:,0] \n",
    "    is_pos_int = is_pos.astype(np.int32)\n",
    "    correct = is_pos_int == y\n",
    "\n",
    "    sum_weights = np.sum(y_weights)\n",
    "\n",
    "    correct_float = correct.astype(np.float32)\n",
    "    weighted_correct_float = correct_float * y_weights\n",
    "    weighted_num_correct = np.sum(weighted_correct_float)\n",
    "    accuracy = weighted_num_correct / sum_weights\n",
    "\n",
    "    return accuracy, weighted_num_correct, sum_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "1c7ZOeO0jCYN",
    "outputId": "a2a7414d-0168-4c55-b31f-bf263718c330"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's prediction accuracy on a single training batch is: 100.0%\n",
      "Weighted number of correct predictions 64.0; weighted number of total observations predicted 64\n"
     ]
    }
   ],
   "source": [
    "# test function\n",
    "tmp_val_generator = val_generator(64)\n",
    "\n",
    "# get one batch\n",
    "tmp_batch = next(tmp_val_generator)\n",
    "\n",
    "# Position 0 has the model inputs (tweets as tensors)\n",
    "# position 1 has the targets (the actual labels)\n",
    "tmp_inputs, tmp_targets, tmp_example_weights = tmp_batch\n",
    "\n",
    "# feed the tweet tensors into the model to get a prediction\n",
    "tmp_pred = training_loop.eval_model(tmp_inputs)\n",
    "\n",
    "tmp_acc, tmp_num_correct, tmp_num_predictions = compute_accuracy(preds=tmp_pred, y=tmp_targets, y_weights=tmp_example_weights)\n",
    "\n",
    "print(f\"Model's prediction accuracy on a single training batch is: {100 * tmp_acc}%\")\n",
    "print(f\"Weighted number of correct predictions {tmp_num_correct}; weighted number of total observations predicted {tmp_num_predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h2ep7nNejCYP"
   },
   "source": [
    "##### Expected output (Approximately)\n",
    "\n",
    "```\n",
    "Model's prediction accuracy on a single training batch is: 100.0%\n",
    "Weighted number of correct predictions 64.0; weighted number of total observations predicted 64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dqle69F1grhM"
   },
   "source": [
    "### Testing model on Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKoTad4ggrhN"
   },
   "outputs": [],
   "source": [
    "def test_model(generator, model):\n",
    "    '''\n",
    "    Input: \n",
    "        generator: an iterator instance that provides batches of inputs and targets\n",
    "        model: a model instance \n",
    "    Output: \n",
    "        accuracy: float corresponding to the accuracy\n",
    "    '''\n",
    "    \n",
    "    accuracy = 0.\n",
    "    total_num_correct = 0\n",
    "    total_num_pred = 0\n",
    "    \n",
    "    for batch in generator: \n",
    "        inputs = batch[0]\n",
    "        targets = batch[1]\n",
    "        example_weight = batch[2]\n",
    "        pred = model(inputs)\n",
    "        \n",
    "        # Calculate accuracy for the batch\n",
    "        batch_accuracy, batch_num_correct, batch_num_pred = compute_accuracy(pred, targets, example_weight)\n",
    "\n",
    "        total_num_correct += batch_num_correct\n",
    "        total_num_pred += batch_num_pred\n",
    "\n",
    "    # Calculate accuracy over all examples\n",
    "    accuracy = total_num_correct/total_num_pred\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1Rm_k21XgrhQ",
    "outputId": "65957ec4-d72b-4363-a5c2-20aa071e9005"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of your model on the validation set is 0.9931\n"
     ]
    }
   ],
   "source": [
    "# testing the accuracy of model\n",
    "model = training_loop.eval_model\n",
    "accuracy = test_model(test_generator(16), model)\n",
    "\n",
    "print(f'The accuracy of your model on the validation set is {accuracy:.4f}', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SUq5cw-xgrhU"
   },
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    inputs = np.array(tweet_to_tensor(sentence, vocab_dict=Vocab))\n",
    "    inputs = inputs[None, :]  \n",
    "    \n",
    "    preds_probs = model(inputs)\n",
    "    preds = int(preds_probs[0, 1] > preds_probs[0, 0])\n",
    "    \n",
    "    sentiment = \"negative\"\n",
    "    if preds == 1:\n",
    "        sentiment = 'positive'\n",
    "\n",
    "    return preds, sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "3RJntC57grhX",
    "outputId": "01f92c2d-738f-424b-d2b0-6e1f6ade4fef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the sentence \n",
      "***\n",
      "\"It's such a nice day, think i'll be taking Sid to Ramsgate fish and chips for lunch at Peter's fish factory and then the beach maybe\"\n",
      "***\n",
      "is positive.\n",
      "\n",
      "The sentiment of the sentence \n",
      "***\n",
      "\"I hated my day, it was the worst, I'm so sad.\"\n",
      "***\n",
      "is negative.\n"
     ]
    }
   ],
   "source": [
    "# ositive sentence\n",
    "sentence = \"It's such a nice day, think i'll be taking Sid to Ramsgate fish and chips for lunch at Peter's fish factory and then the beach maybe\"\n",
    "tmp_pred, tmp_sentiment = predict(sentence)\n",
    "print(f\"The sentiment of the sentence \\n***\\n\\\"{sentence}\\\"\\n***\\nis {tmp_sentiment}.\")\n",
    "\n",
    "print()\n",
    "# negative sentence\n",
    "sentence = \"I hated my day, it was the worst, I'm so sad.\"\n",
    "tmp_pred, tmp_sentiment = predict(sentence)\n",
    "print(f\"The sentiment of the sentence \\n***\\n\\\"{sentence}\\\"\\n***\\nis {tmp_sentiment}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nZmGCheXjCYX"
   },
   "source": [
    "Notice that the model works well even for complex sentences."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "C3_W1_Assignment_Solution.ipynb",
   "provenance": []
  },
  "coursera": {
   "schema_names": [
    "NLPC3-1A"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
